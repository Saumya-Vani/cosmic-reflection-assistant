{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFp-0DupKDl8",
        "outputId": "f2a57ef9-0c23-4097-a460-1d6a38147213"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.56 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.58)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.24 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.24)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.38)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.24->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.56->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.17)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.56->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.24->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.58)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.76.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.3.38)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain-openai) (2.11.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain-openai) (3.10.17)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain-openai) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.58->langchain-openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi\n",
        "!pip install tiktoken\n",
        "!pip install -U langchain-community\n",
        "!pip install pypdf\n",
        "!pip install uvicorn\n",
        "!pip install faiss-cpu\n",
        "!pip install geopy\n",
        "!pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_4x4pP3u3cXn"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import pickle\n",
        "import threading\n",
        "from pathlib import Path\n",
        "from typing import List, Tuple, Optional\n",
        "from datetime import datetime\n",
        "import nest_asyncio\n",
        "import requests\n",
        "from dateutil import parser as dtparser\n",
        "from uvicorn import Config, Server\n",
        "from fastapi import FastAPI, UploadFile, File, HTTPException, Body\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from pydantic import BaseModel, Field, validator\n",
        "\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores.faiss import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from google.colab import userdata\n",
        "from geopy.geocoders import Nominatim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "BsICFe9e3hlN"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "FREE_ASTRO_API_KEY = userdata.get('FREE_ASTRO_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "sMSrPARuK3Cf"
      },
      "outputs": [],
      "source": [
        "STORE_DIR = Path(\"storage\")\n",
        "INDEX_PATH = STORE_DIR / \"pdf_index.faiss\"\n",
        "CHUNK_CACHE = STORE_DIR / \"pdf_chunks.pkl\"\n",
        "\n",
        "CHUNK_SIZE = 1000\n",
        "CHUNK_OVERLAP = 150\n",
        "LOCK = threading.Lock()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCzDvkJcNc4g"
      },
      "source": [
        "# Upload PDFs from GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSUT9CC8NiJV",
        "outputId": "7e181a56-989b-40cc-a784-12a10ca7bf9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "PDF_DIR = \"/content/drive/MyDrive/GenAI Project/pdfs\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hliwE5MFLAT5"
      },
      "source": [
        "# PDF indexing helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "aOz1F9mDK9wp"
      },
      "outputs": [],
      "source": [
        "def load_and_index_pdfs(pdf_dir):\n",
        "    docs = []\n",
        "    for path in glob.glob(f\"{pdf_dir}/*.pdf\"):\n",
        "        docs.extend(PyPDFLoader(path).load())\n",
        "\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
        "    chunks = splitter.split_documents(docs)\n",
        "\n",
        "    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "    vec = FAISS.from_documents(chunks, embeddings)\n",
        "    vec.save_local(INDEX_PATH)\n",
        "\n",
        "    with open(CHUNK_CACHE, \"wb\") as fh:\n",
        "        pickle.dump(chunks, fh)\n",
        "    return vec\n",
        "\n",
        "vectorstore = load_and_index_pdfs(PDF_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zzk-b8e-YYwR"
      },
      "source": [
        "# Reuse vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YGXMEhHRYWW4"
      },
      "outputs": [],
      "source": [
        "nest_asyncio.apply()\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
        "\n",
        "condense_question_prompt = PromptTemplate.from_template(\n",
        "    \"Given this follow-up question, rephrase it as a standalone question:\\n\\n\"\n",
        "    \"“{question}”\\n\\n\"\n",
        "    \"Standalone question:\"\n",
        ")\n",
        "\n",
        "qa_prompt = PromptTemplate.from_template(\n",
        "    \"You are Lumina, a friendly and intelligent assistant.\\n\"\n",
        "    \"Speak in a warm, conversational tone, like you're helping a friend.\\n\"\n",
        "    \"Use only the context from the provided PDFs. If you're not sure, say something like:\\n\"\n",
        "    \"'Hmm, I couldn't find that in the document, but let me know if you'd like to rephrase it.'\\n\\n\"\n",
        "    \"CONTEXT:\\n{context}\\n\\n\"\n",
        "    \"QUESTION: {question}\\n\"\n",
        "    \"ANSWER:\"\n",
        ")\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4o-mini\",\n",
        "    temperature=0,\n",
        "    openai_api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "chain = None\n",
        "\n",
        "def ensure_chain_initialized():\n",
        "    global chain\n",
        "    if chain is None:\n",
        "        print(\"Lumina: Initializing document assistant...\")\n",
        "        chain = ConversationalRetrievalChain.from_llm(\n",
        "            llm=llm,\n",
        "            retriever=retriever,\n",
        "            condense_question_prompt=condense_question_prompt,\n",
        "            combine_docs_chain_kwargs={\"prompt\": qa_prompt},\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJsnMJHOHPQl"
      },
      "source": [
        "# Astro helpers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "53VgJs94HNb7"
      },
      "outputs": [],
      "source": [
        "ASTRO_KEY = FREE_ASTRO_API_KEY\n",
        "ASTRO_HEADERS = {\"Content-Type\": \"application/json\", \"x-api-key\": ASTRO_KEY}\n",
        "def astro_api(endpoint, payload):\n",
        "    resp = requests.post(f\"https://json.freeastrologyapi.com/{endpoint}\", json=payload, headers=ASTRO_HEADERS)\n",
        "    return resp.json().get(\"output\", {})\n",
        "\n",
        "def get_charts(dt, lat, lon, tz):\n",
        "    payload = {\n",
        "        \"year\": dt.year, \"month\": dt.month, \"date\": dt.day,\n",
        "        \"hours\": dt.hour, \"minutes\": dt.minute, \"seconds\": dt.second,\n",
        "        \"latitude\": lat, \"longitude\": lon, \"timezone\": tz,\n",
        "        \"settings\": {\"observation_point\": \"topocentric\", \"ayanamsha\": \"lahiri\"},\n",
        "    }\n",
        "    return {\n",
        "        \"rasi\": astro_api(\"planets\", payload),\n",
        "        \"navamsa\": astro_api(\"navamsa-chart-info\", payload)\n",
        "    }\n",
        "\n",
        "def summarize_personality(name, charts):\n",
        "    prompt = (\n",
        "      f\"You are an insightful astrology guide. Based on the following charts, describe {name}'s personality in a warm, human tone. \"\n",
        "      f\"Speak like you're having a personal conversation with {name}. Keep it under 120 words.\\n\\n\"\n",
        "      f\"# Rasi\\n{charts['rasi']}\\n\\n# Navamsa\\n{charts['navamsa']}\\n\\nAnswer:\"\n",
        "    )\n",
        "    return llm.invoke(prompt).content.strip()\n",
        "\n",
        "def get_coordinates_from_location(location_name):\n",
        "    geolocator = Nominatim(user_agent=\"lumina_assistant\")\n",
        "    location = geolocator.geocode(location_name)\n",
        "    if not location:\n",
        "        raise ValueError(f\"Could not find coordinates for '{location_name}'\")\n",
        "    return location.latitude, location.longitude\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vYYG50EHZPJ"
      },
      "source": [
        "# API Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8sjsxIjHcsv",
        "outputId": "f939be6c-ce64-4ea3-96ac-10a7123c230c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-3e40e66c1b57>:16: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  @validator(\"date\", \"time\")\n"
          ]
        }
      ],
      "source": [
        "class QueryRequest(BaseModel):\n",
        "    question: str\n",
        "    chat_history: Optional[List[Tuple[str, str]]] = None\n",
        "\n",
        "class QueryResponse(BaseModel):\n",
        "    answer: str\n",
        "\n",
        "class AstroRequest(BaseModel):\n",
        "    name: str\n",
        "    date: str\n",
        "    time: str\n",
        "    latitude: float\n",
        "    longitude: float\n",
        "    timezone: float = 0.0\n",
        "\n",
        "    @validator(\"date\", \"time\")\n",
        "    def check_not_empty(cls, v): return v or ValueError(\"Cannot be empty\")\n",
        "\n",
        "    def to_datetime(self): return dtparser.parse(f\"{self.date} {self.time}\")\n",
        "\n",
        "class AstroResponse(BaseModel):\n",
        "    nature: str\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/query\", response_model=QueryResponse)\n",
        "def handle_query(req: QueryRequest):\n",
        "    result = chain.invoke({\"question\": req.question, \"chat_history\": req.chat_history or []})\n",
        "    return QueryResponse(answer=result[\"answer\"].strip())\n",
        "\n",
        "@app.post(\"/astro\", response_model=AstroResponse)\n",
        "def handle_astro(req: AstroRequest):\n",
        "    dt = req.to_datetime()\n",
        "    charts = get_charts(dt, req.latitude, req.longitude, req.timezone)\n",
        "    return AstroResponse(nature=summarize_personality(req.name, charts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we3S0BghHoJC"
      },
      "source": [
        "# Run app in loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "l7E1coGTLmKt"
      },
      "outputs": [],
      "source": [
        "def answer_with_pdfs(question, chat_history):\n",
        "    docs = retriever.invoke(question)\n",
        "    if not docs:\n",
        "        return \"Hmm, I couldn’t find anything about that in my PDFs. Want to try rephrasing your question?\"\n",
        "    ensure_chain_initialized()\n",
        "    result = chain.invoke({\"question\": question, \"chat_history\": chat_history})\n",
        "    return result[\"answer\"].strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Vw95ebTcTppm"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from dateutil import parser as dtparser\n",
        "\n",
        "chat_history = []\n",
        "\n",
        "pdf_affirmations = [\n",
        "    \"Sure, let me check that for you.\",\n",
        "    \"Here’s what I found.\",\n",
        "    \"Looking into the document now.\",\n",
        "]\n",
        "\n",
        "astro_intro_lines = [\n",
        "    \"I'd be happy to explore the birth chart with you.\",\n",
        "    \"Let's take a look at the astrological profile.\",\n",
        "    \"Switching to astrology mode.\",\n",
        "    \"I’ll need the birth details to get started.\"\n",
        "]\n",
        "\n",
        "error_lines = [\n",
        "    \"Something went wrong while processing that.\",\n",
        "    \"I'm having trouble with that. Want to try again?\",\n",
        "    \"That didn’t work as expected — please double-check the input.\"\n",
        "]\n",
        "\n",
        "def run_chat_loop():\n",
        "    print(\"\\nWelcome to Lumina – your intelligent assistant for Vedic Astrology & personality summaries.\\n\")\n",
        "    print(\"I can help you with:\")\n",
        "    print(\"  1. Answering questions related to Vedic astrology concepts, planetary roles, charts, and principles.\")\n",
        "    print(\"  2. Summarizing your personality and behavioral traits using your birth details based on Vedic astrology.\\n\")\n",
        "    print(\"Just type your question to begin. Type 'exit' to end the session.\\n\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"You: \").strip()\n",
        "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "            print(\"\\nLumina: Until next time. Take care.\")\n",
        "            break\n",
        "\n",
        "        astro_keywords = [\"horoscope\", \"personality\", \"planets\"]\n",
        "        is_astro = any(word in user_input.lower() for word in astro_keywords)\n",
        "\n",
        "        if is_astro:\n",
        "            print(random.choice(astro_intro_lines))\n",
        "            try:\n",
        "                name = input(\"Name: \")\n",
        "                date = input(\"Date of Birth (YYYY-MM-DD): \")\n",
        "                time = input(\"Time of Birth (HH:MM, 24hr format): \")\n",
        "                location = input(\"City or Location Name (e.g. Dublin): \")\n",
        "                latitude, longitude = get_coordinates_from_location(location)\n",
        "                print(f\"Resolved Location: {location} -> Latitude: {latitude}, Longitude: {longitude}\")\n",
        "                timezone = float(input(\"Timezone Offset (e.g. 0.0 for Dublin): \"))\n",
        "\n",
        "                dt = dtparser.parse(f\"{date} {time}\")\n",
        "                print(f\"\\nSummarising {name}'s personality...\")\n",
        "                charts = get_charts(dt, latitude, longitude, timezone)\n",
        "                response = summarize_personality(name, charts)\n",
        "\n",
        "                print(\"\\nLumina:\", response, \"\\n\")\n",
        "            except Exception as e:\n",
        "                print(\"\\nLumina:\", random.choice(error_lines))\n",
        "                print(\"Error:\", e, \"\\n\")\n",
        "        else:\n",
        "            try:\n",
        "                print(random.choice(pdf_affirmations))\n",
        "                answer = answer_with_pdfs(user_input, chat_history)\n",
        "                chat_history.append((user_input, answer))\n",
        "                print(\"\\nLumina:\", answer, \"\\n\")\n",
        "            except Exception as e:\n",
        "                print(\"\\nLumina: I'm having trouble answering that based on the documents.\")\n",
        "                print(\"Error:\", e, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEFn4IeDVW7I",
        "outputId": "572f245e-73af-40ce-8667-8eacff92771c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Welcome to Lumina – your intelligent assistant for Vedic Astrology & personality summaries.\n",
            "\n",
            "I can help you with:\n",
            "  1. Answering questions related to Vedic astrology concepts, planetary roles, charts, and principles.\n",
            "  2. Summarizing your personality and behavioral traits using your birth details based on Vedic astrology.\n",
            "\n",
            "Just type your question to begin. Type 'exit' to end the session.\n",
            "\n",
            "You: what is karma?\n",
            "Looking into the document now.\n",
            "\n",
            "Lumina: Karma is a Sanskrit term that comes from the verb-root \"kri,\" which means to act, do, or make. It embodies the principle of causation, highlighting the relationship between our actions and their consequences. Essentially, karma reflects how our actions, thoughts, emotional states, and overall consciousness shape our life experiences. It's a way of understanding that what we do—both good and bad—has a ripple effect, influencing not just our current life but also how we carry those influences into future lives through reincarnation. So, in a nutshell, karma is about the cumulative sum of our actions and their impact on our journey through life. \n",
            "\n",
            "You: what is anxiety?\n",
            "Looking into the document now.\n",
            "\n",
            "Lumina: Hmm, I couldn't find that in the document, but let me know if you'd like to rephrase it. \n",
            "\n",
            "You: good\n",
            "Sure, let me check that for you.\n",
            "\n",
            "Lumina: In the context provided, \"good\" refers to positive attributes or outcomes associated with various aspects of life. For example, it can signify fortune, respect, prosperity, fame, and happiness. These \"good\" qualities often lead to a fulfilling and successful life, encompassing emotional stability, wealth, and positive relationships. Essentially, \"good\" represents beneficial experiences and traits that contribute to overall well-being and satisfaction. If you have any specific area in mind where you'd like to explore what \"good\" means, just let me know! \n",
            "\n",
            "You: bye\n",
            "\n",
            "Lumina: Until next time. Take care.\n"
          ]
        }
      ],
      "source": [
        "run_chat_loop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
